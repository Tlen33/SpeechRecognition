{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ Lite \"Распознавание голосовых команд. SpeechRecognition\".ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPbvBLfzjsM6ad+DS3LTJcF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tlen33/SpeechRecognition/blob/main/%D0%A0%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B3%D0%BE%D0%BB%D0%BE%D1%81%D0%BE%D0%B2%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%B0%D0%BD%D0%B4_SpeechRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmZJEM0Ly4g1",
        "outputId": "bc34507f-ee37-4b56-e452-1cc17c8c9b4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "\n",
        "!pip install SpeechRecognition\n",
        "import speech_recognition as sR\n",
        "!pip install jiwer \n",
        "from jiwer import wer\n",
        "!pip install ffmpeg-python\n",
        "import ffmpeg\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab import files\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "from keras.optimizers import Adam, RMSprop, Adadelta\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "import numpy as np\n",
        "import io\n",
        "import scipy\n",
        "import librosa\n",
        "import os\n",
        "import IPython.display as ipd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27qXHXsqy61-",
        "outputId": "a01469a5-05ae-4af9-d325-777fb81c23d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 89.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting python-Levenshtein==0.12.2\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149860 sha256=6155ea356986220239a78899225a5b58214bb08dad2380d964329efc0ac2991c\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein, jiwer\n",
            "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключение диска\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljQIZksJzjNI",
        "outputId": "10f0df50-48bc-41c5-babe-48706f4a4394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция распознавания аудио с помощью speech_recognition\n",
        "\n",
        "def recognizeAudio(filename, duration=None):\n",
        "  AUDIO_FILE = os.path.join(filename)\n",
        "  r = sR.Recognizer()\n",
        "  with sR.AudioFile(AUDIO_FILE) as source:\n",
        "    audio = r.record(source, duration=duration)\n",
        "\n",
        "  return r.recognize_google(audio, language='ru')"
      ],
      "metadata": {
        "id": "OqQvKPCEzsDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция извлечения аудио, записанного через микрофон в ноутбуке\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>  // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n",
        "var my_div = document.createElement(\"DIV\");  // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n",
        "var my_p = document.createElement(\"P\");  // создаем новый элемент P(параграф для логической группировки текста)\n",
        "var my_btn = document.createElement(\"BUTTON\");  // создаем новый элемент(кнопку) BUTTON\n",
        "var t = document.createTextNode(\"Press to start recording\");  // создаем текстовое содержимое для кнопки\n",
        "\n",
        "my_btn.appendChild(t);  // добавляем текстовое содержимое элементу BUTTON\n",
        "my_div.appendChild(my_btn);  // кнопку с текстом BUTTON добавляем в блок DIV\n",
        "document.body.appendChild(my_div);  // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n",
        "\n",
        "var base64data = 0;  // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n",
        "var reader;  // создаем переменную для чтения файла\n",
        "var recorder, gumStream; // объявляем переменные для записи данных/потока\n",
        "var recordButton = my_btn; //  создаем переменную для кнопки записи аудио с микрофона\n",
        "\n",
        "var handleSuccess = function(stream) {  // объявляем функцию для работы с потоками данных\n",
        "  gumStream = stream;  // создаем переменную для потока\n",
        "  var options = {\n",
        "    mimeType : 'audio/webm;codecs=opus' // в опциях задаем медиа тип с аудиоформатом и кодеками\n",
        "  };            \n",
        "  recorder = new MediaRecorder(stream); // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n",
        "  // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n",
        "  // ..с использованием MediaRecorder() конструктора.\n",
        "  recorder.ondataavailable = function(e) {  // вызываем обработчик dataavailable события, запускаемое по окончанию записи          \n",
        "    var url = URL.createObjectURL(e.data); // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n",
        "    var preview = document.createElement('audio'); // создаем элемент-тег аудио\n",
        "    preview.controls = true; // активизируем элементы управления\n",
        "    preview.src = url; // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n",
        "    document.body.appendChild(preview); //добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n",
        "\n",
        "    reader = new FileReader();  // создаем объект класса FileReader для чтения разных источников данных\n",
        "    reader.readAsDataURL(e.data);  // читаем содержимое указанного файла\n",
        "    reader.onloadend = function() {  // обработчик события, запускаемого после передачи данных\n",
        "      base64data = reader.result; // записываем прочитанное содержимое в base64data\n",
        "    }\n",
        "  };\n",
        "  recorder.start();  // начало записи медиа\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Идёт запись... нажмите для остановки\"; // такой текст будет на кнопке BUTTON во время записи аудио\n",
        "\n",
        "// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n",
        "  if (recorder && recorder.state == \"recording\") {  // если рекордер находится в процессе записи \n",
        "      recorder.stop();  // рекордер прерывается\n",
        "      gumStream.getAudioTracks()[0].stop();  // отключается запись и доступ к микрофону\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\" // эта надпись(сохранение записи) отобразится на кнопке BUTTON \n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {  // создаем функцию с задержкой вызова\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));  \n",
        "  // new Promise - конструкция для отложенных вычислений\n",
        "  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "recordButton.onclick = ()=>{  // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n",
        "toggleRecording()  // вызывается функция завершения аудиозаписи\n",
        "\n",
        "sleep(2000).then(() => {  // и после задержки 2000мс(2 сек)\n",
        "  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True))\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  scipy.io.wavfile.write('recording1.wav', sr, audio)\n",
        "\n",
        "  filename = 'recording1.wav'\n",
        "\n",
        "  def recognizeAudio(filename, duration=None):\n",
        "    AUDIO_FILE = os.path.join(filename)\n",
        "    r = sR.Recognizer()\n",
        "    with sR.AudioFile(AUDIO_FILE) as source:\n",
        "      audio = r.record(source, duration=duration)\n",
        "    return r.recognize_google(audio, language='ru')\n",
        "  \n",
        "  res = recognizeAudio(filename, duration=None)\n",
        "  \n",
        "  return print(res)"
      ],
      "metadata": {
        "id": "OoSYtV7z2lQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запись аудио через микрофон\n",
        "\n",
        "res = get_audio()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "9Z6gpoKjAkJ_",
        "outputId": "01e0e2b4-151e-4b83-b66b-804379bf4af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>  // создаем тег <script>, сообщающий браузеру о том, что внутри находится исполняемый код JavaScript\n",
              "var my_div = document.createElement(\"DIV\");  // создаем новый элемент DIV(тег-контейнер для логического выделения блока документа)\n",
              "var my_p = document.createElement(\"P\");  // создаем новый элемент P(параграф для логической группировки текста)\n",
              "var my_btn = document.createElement(\"BUTTON\");  // создаем новый элемент(кнопку) BUTTON\n",
              "var t = document.createTextNode(\"Press to start recording\");  // создаем текстовое содержимое для кнопки\n",
              "\n",
              "my_btn.appendChild(t);  // добавляем текстовое содержимое элементу BUTTON\n",
              "my_div.appendChild(my_btn);  // кнопку с текстом BUTTON добавляем в блок DIV\n",
              "document.body.appendChild(my_div);  // добавляем наш блок в элемент <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "var base64data = 0;  // будем использовать для аудиоданных метод кодирования информации в 64-разрядный код\n",
              "var reader;  // создаем переменную для чтения файла\n",
              "var recorder, gumStream; // объявляем переменные для записи данных/потока\n",
              "var recordButton = my_btn; //  создаем переменную для кнопки записи аудио с микрофона\n",
              "\n",
              "var handleSuccess = function(stream) {  // объявляем функцию для работы с потоками данных\n",
              "  gumStream = stream;  // создаем переменную для потока\n",
              "  var options = {\n",
              "    mimeType : 'audio/webm;codecs=opus' // в опциях задаем медиа тип с аудиоформатом и кодеками\n",
              "  };            \n",
              "  recorder = new MediaRecorder(stream); // создаем новый объект MediaRecorder, получающий медиапоток для записи.\n",
              "  // MediaRecorder - интерфейс MediaStream Recording API представляющий функциональность для простой записи медиа. Создается..\n",
              "  // ..с использованием MediaRecorder() конструктора.\n",
              "  recorder.ondataavailable = function(e) {  // вызываем обработчик dataavailable события, запускаемое по окончанию записи          \n",
              "    var url = URL.createObjectURL(e.data); // этим методом создаем DOMString(UTF-16 String), содержащий URL с указанием на объект e.data\n",
              "    var preview = document.createElement('audio'); // создаем элемент-тег аудио\n",
              "    preview.controls = true; // активизируем элементы управления\n",
              "    preview.src = url; // берем в кач-ве исходных данных файл, содержащийся в записанной ранее URL\n",
              "    document.body.appendChild(preview); //добавляем элемент аудио в <body>(\"тело\", для хранения содержимого веб-страницы)\n",
              "\n",
              "    reader = new FileReader();  // создаем объект класса FileReader для чтения разных источников данных\n",
              "    reader.readAsDataURL(e.data);  // читаем содержимое указанного файла\n",
              "    reader.onloadend = function() {  // обработчик события, запускаемого после передачи данных\n",
              "      base64data = reader.result; // записываем прочитанное содержимое в base64data\n",
              "    }\n",
              "  };\n",
              "  recorder.start();  // начало записи медиа\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Идёт запись... нажмите для остановки\"; // такой текст будет на кнопке BUTTON во время записи аудио\n",
              "\n",
              "// запрос разрешения пользователя на доступ к устройству захвата аудио(микрофон), указываем True\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {  // функция опишет действия по завершению записи (после клика мышкой по кнопке \"Recording... press to stop\")\n",
              "  if (recorder && recorder.state == \"recording\") {  // если рекордер находится в процессе записи \n",
              "      recorder.stop();  // рекордер прерывается\n",
              "      gumStream.getAudioTracks()[0].stop();  // отключается запись и доступ к микрофону\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\" // эта надпись(сохранение записи) отобразится на кнопке BUTTON \n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {  // создаем функцию с задержкой вызова\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));  \n",
              "  // new Promise - конструкция для отложенных вычислений\n",
              "  // setTimeout позволяет вызвать функцию один раз через определённый интервал времени\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "recordButton.onclick = ()=>{  // при нажатии левой кнопкой мыши на кнопку \"Recording... press to stop\"\n",
              "toggleRecording()  // вызывается функция завершения аудиозаписи\n",
              "\n",
              "sleep(2000).then(() => {  // и после задержки 2000мс(2 сек)\n",
              "  resolve(base64data.toString())  // полученные данные из формата base64 преобразовываем в строку\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет Как дела\n"
          ]
        }
      ]
    }
  ]
}